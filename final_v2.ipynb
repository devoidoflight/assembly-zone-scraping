{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.client\n",
    "import json\n",
    "import urllib.parse\n",
    "import re\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse the curl bash command into usable components\n",
    "def clean_curl_request(curl_command):\n",
    "    # Extract the URL\n",
    "    url_pattern = r\"curl '(.*?)'\"\n",
    "    match = re.search(url_pattern, curl_command)\n",
    "    if match:\n",
    "        url = match.group(1)\n",
    "    else:\n",
    "        raise ValueError(\"URL not found in the curl command\")\n",
    "\n",
    "    # Extract headers\n",
    "    headers = {}\n",
    "    header_pattern = r\"-H '([^:]+): (.*?)'\"\n",
    "    for header_match in re.finditer(header_pattern, curl_command):\n",
    "        header_name = header_match.group(1)\n",
    "        header_value = header_match.group(2)\n",
    "        headers[header_name] = header_value\n",
    "\n",
    "    # Extract data\n",
    "    data_pattern = r\"--data-raw '(.*?)'\"\n",
    "    match = re.search(data_pattern, curl_command)\n",
    "    data = {}\n",
    "    if match:\n",
    "        data_string = match.group(1)\n",
    "        data_items = data_string.split(\"&\")\n",
    "        for item in data_items:\n",
    "            key, value = item.split(\"=\")\n",
    "            data[key] = urllib.parse.unquote(value)\n",
    "\n",
    "    # Parse URL for host and path\n",
    "    parsed_url = urllib.parse.urlparse(url)\n",
    "    host = parsed_url.netloc\n",
    "    path = parsed_url.path + (\"?\" + parsed_url.query if parsed_url.query else \"\")\n",
    "\n",
    "    return host, path, data, headers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to send requests dynamically\n",
    "def send_request(host, path, data, headers, lat, lng):\n",
    "    # Update latitude and longitude in the data dictionary\n",
    "    data[\"lat\"] = str(lat)\n",
    "    data[\"lng\"] = str(lng)\n",
    "\n",
    "    # Set up the connection\n",
    "    connection = http.client.HTTPSConnection(host)\n",
    "\n",
    "    # Send the POST request\n",
    "    connection.request(\"POST\", path, body=urllib.parse.urlencode(data), headers=headers)\n",
    "\n",
    "    # Get the response\n",
    "    response = connection.getresponse()\n",
    "    response_data = response.read().decode()\n",
    "\n",
    "    # Close the connection\n",
    "    connection.close()\n",
    "\n",
    "    # Check for a successful response and return the result\n",
    "    if response.status == 200:\n",
    "        return json.loads(response_data)\n",
    "    else:\n",
    "        return f\"Error: {response.status}, {response_data}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file():\n",
    "    # Poligonun icindeki noktaları buraya ekleyecegiz.\n",
    "    with open('istanbul-admin-level-6.geojson', 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_properties(data,ilce):\n",
    "    for i in data[\"features\"]:\n",
    "        print(i[\"properties\"].get(\"name\", \"point\"))\n",
    "        # Polygonları alıyoruz sadece\n",
    "        if i[\"geometry\"].get(\"type\", \"unnamed\") != \"Point\" and i[\"properties\"].get(\"name\", \"point\") == ilce:\n",
    "            name = i[\"properties\"].get(\"name\", \"point\")\n",
    "            geometry_type = i[\"geometry\"].get(\"type\", \"point\")\n",
    "            coordinates = i[\"geometry\"].get(\"coordinates\", \"point\")\n",
    "            # Polygon olanları direkt listeye atıyoruz.\n",
    "            if geometry_type == \"Polygon\":\n",
    "                polygons = [Polygon(coordinates[0])]\n",
    "            # Multi-poly olanları listeler icinde listeye atıyoruz.\n",
    "            elif geometry_type == \"MultiPolygon\":\n",
    "                polygons = [Polygon(polygon[0]) for polygon in coordinates]\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported geometry type: {geometry_type}\")\n",
    "    return name,geometry_type,polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_exterior_coordinates_create_lines(aralık=100,polygons):\n",
    "    for polygon in polygons:\n",
    "        # Extract exterior coordinates for plotting\n",
    "        lat_spacing = aralik / 111320  # Approximation: 1 degree latitude ~ 111.32 km\n",
    "        min_lat = min([min(polygon.exterior.coords.xy[1]) for polygon in polygons])\n",
    "        max_lat = max([max(polygon.exterior.coords.xy[1]) for polygon in polygons])\n",
    "        lat_lines = np.arange(min_lat, max_lat, lat_spacing)\n",
    "\n",
    "        for lat in lat_lines:\n",
    "            min_lon = min([min(polygon.exterior.coords.xy[0]) for polygon in polygons])\n",
    "            max_lon = max([max(polygon.exterior.coords.xy[0]) for polygon in polygons])\n",
    "            lon_spacing = aralik / (111320 * np.cos(np.radians(lat)))  # Adjust for longitude scaling\n",
    "            lon_points = np.arange(min_lon, max_lon, lon_spacing)\n",
    "    return lon_points,lat_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_dot_inside_the_polygon(point_list):\n",
    "    \n",
    "    for lon in lon_points:\n",
    "     point = Point(lon, lat)\n",
    "     is_inside = any(polygon.contains(point) for polygon in polygons)\n",
    "     if is_inside:\n",
    "         point_list.append((lon, lat))\n",
    "    \n",
    "    return red_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adalar\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'str' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 52\u001b[0m\n\u001b[0;32m     49\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39mcolumns)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lng, lat \u001b[38;5;129;01min\u001b[39;00m red_points:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;66;03m# Send API request\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43msend_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheaders\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlng\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;66;03m# If the request is successful, process the results\u001b[39;00m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m result:\n",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m, in \u001b[0;36msend_request\u001b[1;34m(host, path, data, headers, lat, lng)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_request\u001b[39m(host, path, data, headers, lat, lng):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Update latitude and longitude in the data dictionary\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(lat)\n\u001b[0;32m      5\u001b[0m     data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlng\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(lng)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Set up the connection\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "ilce = 'Adalar'\n",
    "aralik = 100\n",
    "# Listeyi loop'un icinde yaratıyoruz ki ilce ilce alabilelim.\n",
    "red_points = []\n",
    "# # Poligonun icindeki noktaları buraya ekleyecegiz.\n",
    "# with open('istanbul-admin-level-6.geojson', 'r', encoding='utf-8') as file:\n",
    "#     data = json.load(file)\n",
    "\n",
    "#for i in data[\"features\"]:\n",
    "#    print(i[\"properties\"].get(\"name\", \"point\"))\n",
    "#    # Polygonları alıyoruz sadece\n",
    "#    if i[\"geometry\"].get(\"type\", \"unnamed\") != \"Point\" and i[\"properties\"].get(\"name\", \"point\") =! \"Gebze\":\n",
    "#        name = i[\"properties\"].get(\"name\", \"point\")\n",
    "#        geometry_type = i[\"geometry\"].get(\"type\", \"point\")\n",
    "#        coordinates = i[\"geometry\"].get(\"coordinates\", \"point\")\n",
    "#        # Polygon olanları direkt listeye atıyoruz.\n",
    "#        if geometry_type == \"Polygon\":\n",
    "#            polygons = [Polygon(coordinates[0])]\n",
    "#        # Multi-poly olanları listeler icinde listeye atıyoruz.\n",
    "#        elif geometry_type == \"MultiPolygon\":\n",
    "#            polygons = [Polygon(polygon[0]) for polygon in coordinates]\n",
    "#        else:\n",
    "#            raise ValueError(f\"Unsupported geometry type: {geometry_type}\")\n",
    "\n",
    "#        for polygon in polygons:\n",
    "#            # Extract exterior coordinates for plotting\n",
    "#            lat_spacing = aralik / 111320  # Approximation: 1 degree latitude ~ 111.32 km\n",
    "#            min_lat = min([min(polygon.exterior.coords.xy[1]) for polygon in polygons])\n",
    "#            max_lat = max([max(polygon.exterior.coords.xy[1]) for polygon in polygons])\n",
    "#            lat_lines = np.arange(min_lat, max_lat, lat_spacing)\n",
    "#\n",
    "#            for lat in lat_lines:\n",
    "#                min_lon = min([min(polygon.exterior.coords.xy[0]) for polygon in polygons])\n",
    "#                max_lon = max([max(polygon.exterior.coords.xy[0]) for polygon in polygons])\n",
    "#                lon_spacing = aralik / (111320 * np.cos(np.radians(lat)))  # Adjust for longitude scaling\n",
    "#                lon_points = np.arange(min_lon, max_lon, lon_spacing)\n",
    "\n",
    "                # Nokta poligonun icinde mi kontrol ediyoruz icindeyse kırmızı degilse yesil \n",
    "                for lon in lon_points:\n",
    "                    point = Point(lon, lat)\n",
    "                    is_inside = any(polygon.contains(point) for polygon in polygons)\n",
    "                    if is_inside:\n",
    "                        red_points.append((lon, lat))\n",
    "\n",
    "        # DataFrame olustur ve verileri ekle\n",
    "        columns = [\"tesis_adi\", \"il_adi\", \"sokak_adi\", \"ilce_adi\", \"mahalle_adi\", \"lng\", \"lat\", \"id\"]\n",
    "        df = pd.DataFrame(columns=columns)\n",
    "        for lng, lat in red_points:\n",
    "            # Send API request\n",
    "            result = send_request(\"host\", \"path\", \"data\", \"headers\", lat, lng)\n",
    "            # If the request is successful, process the results\n",
    "            if isinstance(result, dict) and \"features\" in result:\n",
    "                for feature in result[\"features\"]:\n",
    "                    # Extract relevant properties\n",
    "                    properties = feature[\"properties\"]\n",
    "                    row = {\n",
    "                        \"tesis_adi\": properties.get(\"tesis_adi\", \"\"),\n",
    "                        \"il_adi\": properties.get(\"il_adi\", \"\"),\n",
    "                        \"sokak_adi\": properties.get(\"sokak_adi\", \"\"),\n",
    "                        \"ilce_adi\": properties.get(\"ilce_adi\", \"\"),\n",
    "                        \"mahalle_adi\": properties.get(\"mahalle_adi\", \"\"),\n",
    "                        \"lng\": properties.get(\"lng\", \"\"),\n",
    "                        \"lat\": properties.get(\"lat\", \"\"),\n",
    "                        \"id\": properties.get(\"id\", \"\")\n",
    "                    }\n",
    "                    # Append the row to the DataFrame\n",
    "                    df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "        # Drop duplicates after each iteration\n",
    "        df.drop_duplicates(subset=[\"id\"], inplace=True)\n",
    "\n",
    "        # Save the final DataFrame to a CSV file\n",
    "        df.to_csv(f\"{name}_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curl_command = \"\"\"\n",
    "curl 'https://www.turkiye.gov.tr/afet-ve-acil-durum-yonetimi-acil-toplanma-alani-sorgulama?harita=goster&submit' \\\n",
    "  -H 'Accept: application/json, text/javascript, */*; q=0.01' \\\n",
    "  -H 'Accept-Language: tr-TR,tr;q=0.9,en-US;q=0.8,en;q=0.7' \\\n",
    "  -H 'Connection: keep-alive' \\\n",
    "  -H 'Content-Type: application/x-www-form-urlencoded; charset=UTF-8' \\\n",
    "  -H 'Cookie: ridbb=WyI1ZWZjYWJjN2E5YzNiY2M4ZDY4OWExMGIwN2IwMTcyMmNjZDc5NjUzZDBlOCJd; _uid=1721632846-0ba03683-f088-45be-ab36-f8dd67f8b32d; w3p=1943251136.20480.0000; language=tr_TR.UTF-8; uyari=b8e23373d48d32ab19013491277695691c051a6639e16343c50db3d9f71adf64; TURKIYESESSIONID=l4c0eutds26b2qr2ghqjf9mbt4; TS015d3f68=015c1cbb6d6bcb6358b3fc4d2387f6b25fa2d1245dfddce1e7b22bd8348a14a1e565feedf84c8944203eed55b58f837e9f56aacdc0; _lastptts=1735847586' \\\n",
    "  -H 'Origin: https://www.turkiye.gov.tr' \\\n",
    "  -H 'Referer: https://www.turkiye.gov.tr/afet-ve-acil-durum-yonetimi-acil-toplanma-alani-sorgulama?harita=goster' \\\n",
    "  -H 'Sec-Fetch-Dest: empty' \\\n",
    "  -H 'Sec-Fetch-Mode: cors' \\\n",
    "  -H 'Sec-Fetch-Site: same-origin' \\\n",
    "  -H 'User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36 OPR/115.0.0.0' \\\n",
    "  -H 'X-Requested-With: XMLHttpRequest' \\\n",
    "  -H 'sec-ch-ua: \"Chromium\";v=\"130\", \"Opera\";v=\"115\", \"Not?A_Brand\";v=\"99\"' \\\n",
    "  -H 'sec-ch-ua-mobile: ?0' \\\n",
    "  -H 'sec-ch-ua-platform: \"Windows\"' \\\n",
    "  --data-raw 'pn=%2Fafet-ve-acil-durum-yonetimi-acil-toplanma-alani-sorgulama&ajax=1&token=%7B6D7A6F-2ED4EB-F96A69-A23803-F7E63C-51CA4D-9AB3C3-BCD5F2%7D&islem=getAlanlarForNokta&lat=40.969583296311086&lng=29.095801512231148'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Parse the curl command\n",
    "host, path, data, headers = clean_curl_request(curl_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Read coordinates from file and process them\n",
    "with open('coordinates.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        try:\n",
    "            # Extract longitude and latitude\n",
    "            lng, lat = map(float, line.strip().split(', '))\n",
    "\n",
    "            # Send API request\n",
    "            result = send_request(host, path, data, headers, lat, lng)\n",
    "\n",
    "            # If the request is successful, process the results\n",
    "            if isinstance(result, dict) and \"features\" in result:\n",
    "                for feature in result[\"features\"]:\n",
    "                    # Extract relevant properties\n",
    "                    properties = feature[\"properties\"]\n",
    "                    row = {\n",
    "                        \"tesis_adi\": properties.get(\"tesis_adi\", \"\"),\n",
    "                        \"il_adi\": properties.get(\"il_adi\", \"\"),\n",
    "                        \"sokak_adi\": properties.get(\"sokak_adi\", \"\"),\n",
    "                        \"ilce_adi\": properties.get(\"ilce_adi\", \"\"),\n",
    "                        \"mahalle_adi\": properties.get(\"mahalle_adi\", \"\"),\n",
    "                        \"lng\": properties.get(\"lng\", \"\"),\n",
    "                        \"lat\": properties.get(\"lat\", \"\"),\n",
    "                        \"id\": properties.get(\"id\", \"\")\n",
    "                    }\n",
    "                    # Append the row to the DataFrame\n",
    "                    df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "            # Drop duplicates after each iteration\n",
    "            df.drop_duplicates(subset=[\"id\"], inplace=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing line '{line.strip()}': {e}\")\n",
    "\n",
    "# Save the final DataFrame to a CSV file\n",
    "df.to_csv(\"api_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
